ğŸ“Œ Project Title
AI-Powered Online Harassment Detection System

ğŸ“– Project Overview

Online platforms face increasing challenges in detecting harassment, abusive language, and threats in real time. Manual moderation is slow, inconsistent, and not scalable.

This project presents an AI-powered harassment detection system that analyzes user-generated text, evaluates risk using multiple AI models, and provides an administrative decision through a live dashboard.

The system is designed to minimize false positives while ensuring high safety, similar to real-world moderation systems used by social media platforms.


ğŸ¯ Objectives

Detect abusive and harassing content automatically

Analyze sentiment, severity, and threat level

Reduce false positives using sentiment-aware logic

Provide real-time moderation decisions

Offer an admin dashboard for visualization and monitoring

monitoring

ğŸ§  Key Features

ğŸ” Harassment Probability Detection (ML classifier)

ğŸ˜Š Sentiment Analysis (NLTK VADER)

ğŸš¨ Threat Detection Module

ğŸ§  Rule-Based Administrative Decision Engine

âš¡ FastAPI REST API

ğŸ“Š Admin Dashboard using Streamlit

â˜ï¸ Cloud Deployment (Render + Streamlit Cloud)

âš™ï¸ Technology Stack

| Layer                | Technology              |
| -------------------- | ----------------------- |
| Programming Language | Python                  |
| Backend Framework    | FastAPI                 |
| ML Models            | Scikit-learn            |
| NLP                  | NLTK (VADER)            |
| API Server           | Uvicorn                 |
| Dashboard            | Streamlit               |
| Deployment           | Render, Streamlit Cloud |
| Version Control      | GitHub                  |


ğŸ§ª Decision Logic (Core Innovation)

The system uses multi-factor decision making:

Harassment probability (ML output)

Sentiment polarity

Threat detection

Severity classification

Example Policy:

Positive sentiment override â†’ avoids false positives

Threat detected â†’ immediate escalation

Medium severity â†’ warning

Low severity â†’ allow content

This mirrors industry-grade moderation pipelines.

ğŸ§  Learning Outcomes

Built an end-to-end AI system from scratch

Integrated ML models with REST APIs

Designed policy-based decision systems

Deployed scalable cloud applications

Reduced ML false positives using sentiment-aware logic

ğŸ† Use Cases

Social media moderation

Online community platforms

Educational discussion forums

Comment filtering systems

ğŸ“Œ Future Enhancements

Transformer-based NLP models (BERT)

Multilingual harassment detection

Image & video moderation

User behavior analytics
